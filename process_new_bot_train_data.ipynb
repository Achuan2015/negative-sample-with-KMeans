{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ssc 的语料，为了避免稀释，选择其中的一半\n",
    "path1 = 'data/ssc_faq_corpus_with_index_20220310.csv'\n",
    "# new bot的语料，整理好的\n",
    "path2 = 'data/bot_corpus_20220516.csv'\n",
    "# 闲聊语料\n",
    "path3 = 'data/small_chat_corpus_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据格式以 bot_corpus_20220516.csv 的格式作为标准\n",
    "## 先合并 path 1 和 path3 的数据\n",
    "df1 = pd.read_csv(path1, sep='\\t')\n",
    "df2 = pd.read_csv(path2, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skill', 'category1', 'question', 'alias', 'category_id', 'skill_id', 'question_id', 'index']\n",
      "['公司介绍', '团队介绍', '薪酬', '绩效', '社保公积金', '居住证', '政策解读', '行为准则', '奖励制度', '惩罚制度', '福利', '补贴', '工会', '员工管理', '会议日程', 'IT运维', '报销', '入职', '转正', '离职', '调岗', '调休', '上下班', '加班', '早退', '迟到', '旷工', '出差', '员工培训', '假期管理', '事假', '病假', '年假', '产假', '陪产假', '婚假', '其他假期', '校招', '通讯录', '公司简介', '企业文化', '我要入职', '我要转正', '我要调岗', '离职流程', '我的考勤', '我的加班', '我要休假', '安全管理', 'EHS管理', '纪律管理', '基本工资', '绩效奖金', '社保', '公司福利', '我的培训', '我的发展', '薪酬政策', '差旅政策', '沟通渠道', '持续改进', '行政服务', 'IT服务', '个人所得税', '公积金', '党组织关系', '证明开具', '上海居住证积分及落户', '财务报销', '奖励', '采购政策']\n",
      "71\n",
      "['公司介绍', '团队介绍', '薪酬', '绩效', '社保公积金', '居住证', '政策解读', '行为准则', '奖励制度', '惩罚制度', '福利', '补贴', '工会', '员工管理', '会议日程', 'IT运维', '报销']\n",
      "17\n",
      "['公司介绍', '团队介绍', '薪酬', '绩效', '社保公积金', '居住证', '政策解读', '行为准则', '奖励制度', '惩罚制度']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns.tolist())\n",
    "\n",
    "print(df1['category1'].drop_duplicates().tolist())\n",
    "print(df1['category1'].drop_duplicates().tolist().__len__())\n",
    "\n",
    "df11 = df1.iloc[:40000]\n",
    "print(df11['category1'].drop_duplicates().tolist())\n",
    "print(df11['category1'].drop_duplicates().tolist().__len__())\n",
    "\n",
    "\n",
    "df111 = df1.iloc[:20000]\n",
    "print(df111['category1'].drop_duplicates().tolist())\n",
    "print(df111['category1'].drop_duplicates().tolist().__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skill', 'category1', 'question', 'alias', 'category_id', 'skill_id', 'question_id', 'index']\n",
      "['我是谁', '我没钱', '我来了', '我走了', '郁闷', '生气', '我渴了', '我饿了', '我输了', '我好累', '我好笨', '我恨你', '我恨他', '你好', '在吗', '早上好', '上午好', '中午好', '下午好', '晚上好', '谢谢', '对不起', '没关系', '辛苦了', '再见', '伤心', '开心', '无聊', '呵呵', '好的', '谁最帅', '谁最美', '我帅吗', '我美吗', '我爱你', '麻烦你', '为什么', '知道了']\n",
      "['category', 'intent_id', 'intent_name', 'corpus_id', 'text']\n",
      "['category', 'intent_name', 'text', 'intent_id']\n",
      "['category', 'intent_name', 'text', 'intent_id', 'corpus_id']\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.iloc[:20000]\n",
    "\n",
    "chat_corpus = []\n",
    "with open(path3, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            chat_corpus.append(line)\n",
    "\n",
    "print(df1.columns.tolist())\n",
    "print(chat_corpus)\n",
    "\n",
    "df1 = df1[['category1', 'question', 'alias', 'question_id']]\n",
    "df1 = df1.rename(columns={'category1': 'category', 'question_id': 'intent_id', 'question': 'intent_name', 'alias': 'text'})\n",
    "chat_corpus_dict = {'text': chat_corpus, 'category': ['small_chat' for _ in range(len(chat_corpus))], \n",
    "                    'intent_name':['small_chat' for _ in range(len(chat_corpus))],\n",
    "                    'intent_id': [90000 for _ in range(len(chat_corpus))]}\n",
    "df3 = pd.DataFrame(chat_corpus_dict)\n",
    "df12 = pd.concat([df1, df3], ignore_index=True)\n",
    "df12['corpus_id'] = df12.index + 1\n",
    "\n",
    "print(df2.columns.tolist())\n",
    "print(df1.columns.tolist())\n",
    "print(df12.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat([df12, df2], ignore_index=True)\n",
    "\n",
    "dfs.to_csv('data/bot_corpus_20220612_v2.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafaadbda7e2b4673c53a13d22366aab1c2a35a28f6b7c4e8046d1a490edd4db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
