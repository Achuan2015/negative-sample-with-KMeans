{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理新增的bot数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zuber_id</th>\n",
       "      <th>intent_id</th>\n",
       "      <th>intent_name</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>text</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>815860776309075968</td>\n",
       "      <td>6IB/推进-FAB-FA-AS</td>\n",
       "      <td>854654812441194496</td>\n",
       "      <td>我们可以清晰的可以清晰的可以看到，然后一周呢，能够快速的缓解，缓缓解患者的这个背痛，然后四周...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>815860776309075968</td>\n",
       "      <td>6IB/推进-FAB-FA-AS</td>\n",
       "      <td>854654812441194497</td>\n",
       "      <td>可申请可以快速控制炎症，缓解中毒症状，一周缓解背痛四周，缓解晨僵和疲劳，那么快速的缓解晨僵、...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>815860776309075968</td>\n",
       "      <td>6IB/推进-FAB-FA-AS</td>\n",
       "      <td>854654812441194498</td>\n",
       "      <td>可善挺可以快速的空盐，缓解中轴的症状呢我们来看一下可善挺的数据，那客栈挺一周就可以缓解背痛四...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>815860776309075968</td>\n",
       "      <td>6IB/推进-FAB-FA-AS</td>\n",
       "      <td>854654812441194499</td>\n",
       "      <td>可善挺治疗后一年缓解背痛，四周改善陈江和疲劳在一周内能够快速的缓解他的悲痛，在一个月内的时间...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>815860776309075968</td>\n",
       "      <td>6IB/推进-FAB-FA-AS</td>\n",
       "      <td>854654812441194500</td>\n",
       "      <td>可身体快速控源，缓解中轴症状，一周即可以缓解背痛四周，缓解晨僵和疲劳。那么咳嗽呢？通过研究结...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zuber_id           intent_id       intent_name           corpus_id  \\\n",
       "0  1000000001  815860776309075968  6IB/推进-FAB-FA-AS  854654812441194496   \n",
       "1  1000000001  815860776309075968  6IB/推进-FAB-FA-AS  854654812441194497   \n",
       "2  1000000001  815860776309075968  6IB/推进-FAB-FA-AS  854654812441194498   \n",
       "3  1000000001  815860776309075968  6IB/推进-FAB-FA-AS  854654812441194499   \n",
       "4  1000000001  815860776309075968  6IB/推进-FAB-FA-AS  854654812441194500   \n",
       "\n",
       "                                                text synonyms  \n",
       "0  我们可以清晰的可以清晰的可以看到，然后一周呢，能够快速的缓解，缓缓解患者的这个背痛，然后四周...      NaN  \n",
       "1  可申请可以快速控制炎症，缓解中毒症状，一周缓解背痛四周，缓解晨僵和疲劳，那么快速的缓解晨僵、...      NaN  \n",
       "2  可善挺可以快速的空盐，缓解中轴的症状呢我们来看一下可善挺的数据，那客栈挺一周就可以缓解背痛四...      NaN  \n",
       "3  可善挺治疗后一年缓解背痛，四周改善陈江和疲劳在一周内能够快速的缓解他的悲痛，在一个月内的时间...      NaN  \n",
       "4  可身体快速控源，缓解中轴症状，一周即可以缓解背痛四周，缓解晨僵和疲劳。那么咳嗽呢？通过研究结...      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/Result_27.csv'\n",
    "path_20220617 = 'data/Result_3_202206017.csv'\n",
    "\n",
    "dfs = pd.read_csv(path_20220617, sep=',', names=['zuber_id', 'intent_id', 'intent_name', 'corpus_id', 'text', 'synonyms'])\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_binary = [\"中行\", \"费卡\", \"6IB\", \"催收\", '赛诺菲', '来优时', '推进']\n",
    "theme_label = ['催收','费卡', '6IB', '推进']\n",
    "\n",
    "def get_category(intent_name, theme):\n",
    "    for t in theme:\n",
    "        if t in intent_name:\n",
    "            return t\n",
    "\n",
    "dfs = dfs.dropna(subset=['text'])\n",
    "dfs['category'] = dfs['intent_name'].apply(lambda x: get_category(x, theme_binary))\n",
    "dfs['category_label'] = dfs['intent_name'].apply(lambda x: get_category(x, theme_label))\n",
    "dfs_binary = dfs.dropna(subset=['category'])\n",
    "dfs_label = dfs.dropna(subset=['category_label'])\n",
    "dfs_binary = dfs_binary.dropna(subset=['text'])\n",
    "dfs_label = dfs_label.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names length: 84\n",
      "[[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "## 查看intent_name 的总数 -》 考虑转换成标签后存在的总数\n",
    "from sklearn import preprocessing\n",
    "\n",
    "names = dfs_label['intent_name'].drop_duplicates().tolist()\n",
    "print(f'names length: {len(names)}')\n",
    "names = [(name,) for name in names]\n",
    "mle = preprocessing.MultiLabelBinarizer()\n",
    "mle.fit(y=names)\n",
    "# print(mle.classes_)\n",
    "for name in names:\n",
    "    mle.transform([name])\n",
    "print(mle.transform([('6IB/推进-FAB-B患者', '6IB-缔结-跟进计划',)]))\n",
    "\n",
    "dfs_temp1= dfs_label[['intent_id', 'intent_name']]\n",
    "dfs_temp2 = dfs_label[['intent_id', 'text']]\n",
    "dfs_temp3 = dfs_label[['intent_id', 'category_label']]\n",
    "\n",
    "intentid2name = dict(zip(dfs_temp1['intent_id'], dfs_temp1['intent_name']))\n",
    "intentid2text = dict(zip(dfs_temp2['intent_id'], dfs_temp2['text']))\n",
    "intentid2category = dict(zip(dfs_temp3['intent_id'], dfs_temp3['category_label']))\n",
    "corpusid2text = dict(zip(dfs_label['corpus_id'], dfs['text']))\n",
    "intent_ids = dfs_label['intent_id'].drop_duplicates().tolist()\n",
    "intentid2corpus_id = {}\n",
    "for intent_id in intent_ids:\n",
    "    intentid2corpus_id[intent_id] = dfs_label[dfs_label['intent_id'] == intent_id]['corpus_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取线上bot的节点意图结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "[[815860776309075968, 815860777558978560], [815860777999380480, 815860778305564672, 815860778603360256], [815860778603360256, 815860778909544448]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "node_path = 'data/tenant_bot_sale_cb_node.csv'\n",
    "column_names = ['node', 'intents']\n",
    "\n",
    "dfs_node = pd.read_csv(node_path, names=column_names)\n",
    "\n",
    "category_counter = []\n",
    "\n",
    "intents_tables = dfs_node['intents'].tolist()\n",
    "intents_table_filter = []\n",
    "for table in intents_tables:\n",
    "    table_list = eval(table)\n",
    "    if len(table_list) > 1:\n",
    "        status = True\n",
    "        temp_table = []\n",
    "        for i in table_list:\n",
    "            if i in intentid2name:\n",
    "                category_counter.append(intentid2category[i])\n",
    "                temp_table.append(i)\n",
    "        if len(temp_table) > 1:\n",
    "            intents_table_filter.append(temp_table)\n",
    "print(len(intents_table_filter))\n",
    "print(intents_table_filter[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 23478\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "multi_label_data = []\n",
    "\n",
    "\n",
    "for intent_table in intents_table_filter:\n",
    "    sample_number = sum([intentid2corpus_id.__len__() for ii in intent_table]) // (len(intent_table) * 2)\n",
    "    cur_sample = []\n",
    "    while len(cur_sample) < sample_number:\n",
    "        text = ''\n",
    "        cur_corpus_id = []\n",
    "        table_label = []\n",
    "        for ii in intent_table:\n",
    "            i = random.choice(intentid2corpus_id[ii])\n",
    "            if len(text) + len(corpusid2text[i]) < 225:\n",
    "                text += corpusid2text[i]\n",
    "                table_label.append(intentid2name[ii])\n",
    "        if len(table_label) > 1:\n",
    "            cur_intent_name = tuple(table_label)\n",
    "            cur_one_hot_label = mle.transform([cur_intent_name])[0]\n",
    "            cur_sample.append((text, intent_table, cur_intent_name, cur_one_hot_label))\n",
    "    multi_label_data.extend(cur_sample)\n",
    "\n",
    "print(f'total: {len(multi_label_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存多标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_label_corpus = pd.DataFrame(multi_label_data, columns=['text', 'intent_id', 'intent_name', 'one_hot_label'])\n",
    "\n",
    "# dfs_label_corpus.to_csv('data/data_corpus_multi_label_20220617.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_single_label = dfs_label[['intent_id', 'intent_name', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造标签数据并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-bc7345670b61>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_single_label['one_hot_label'] = dfs_single_label['intent_name'].apply(lambda x: transform_label(x))\n"
     ]
    }
   ],
   "source": [
    "def transform_label(x):\n",
    "    label= None\n",
    "    if isinstance(x, str):\n",
    "        label = mle.transform([(x,)])[0]\n",
    "    if isinstance(x, list):\n",
    "        label = mle.transform([tuple(x)])[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "dfs_single_label['one_hot_label'] = dfs_single_label['intent_name'].apply(lambda x: transform_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            intent_id       intent_name  \\\n",
      "0  815860776309075968  6IB/推进-FAB-FA-AS   \n",
      "1  815860776309075968  6IB/推进-FAB-FA-AS   \n",
      "\n",
      "                                                text  \\\n",
      "0  我们可以清晰的可以清晰的可以看到，然后一周呢，能够快速的缓解，缓缓解患者的这个背痛，然后四周...   \n",
      "1  可申请可以快速控制炎症，缓解中毒症状，一周缓解背痛四周，缓解晨僵和疲劳，那么快速的缓解晨僵、...   \n",
      "\n",
      "                                       one_hot_label  \n",
      "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "****************************************\n",
      "                                                text  \\\n",
      "0  隔扇体呢，可以达到一个快速控盐，缓解中轴症状的一个目标，它是可以一周缓解背痛四周，缓解晨僵四...   \n",
      "1  就是科三呢，它有一个就是快速控盐，缓解中轴症状的一个优势，那他这边一周是可以缓解背痛四周，缓...   \n",
      "\n",
      "                                  intent_id  \\\n",
      "0  [815860776309075968, 815860777558978560]   \n",
      "1  [815860776309075968, 815860777558978560]   \n",
      "\n",
      "                             intent_name  \\\n",
      "0  (6IB/推进-FAB-FA-AS, 6IB/推进-FAB-FA-PSO)   \n",
      "1  (6IB/推进-FAB-FA-AS, 6IB/推进-FAB-FA-PSO)   \n",
      "\n",
      "                                       one_hot_label  \n",
      "0  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "print(dfs_single_label.head(2))\n",
    "\n",
    "print(\"****\" * 10)\n",
    "print(dfs_label_corpus.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并label 数据，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25987, 2)\n"
     ]
    }
   ],
   "source": [
    "dfs_label_merge = pd.concat([dfs_single_label, dfs_label_corpus], ignore_index=False)\n",
    "\n",
    "dfs_label_train = dfs_label_merge[['text', 'one_hot_label']]\n",
    "print(dfs_label_train.shape)\n",
    "\n",
    "dfs_label_train.to_csv('output_data/data_label_corpus_20220620_v2.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存处理好的数据-0515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_binary = dfs_binary[['category','intent_id', 'intent_name', 'corpus_id', 'text']]\n",
    "\n",
    "\n",
    "dfs_binary.to_csv('data/bot_origin_corpus_20220617.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并不同方法的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path1 = 'output_data/bot_multi_intent_train_20220517_3.csv'\n",
    "path2 = 'output_data/bot_train_20220516_8_2.csv'\n",
    "path3 = 'data/wz_train.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1, sep='\\t')\n",
    "df2 = pd.read_csv(path2, sep='\\t')\n",
    "df3 = pd.read_csv(path3, sep='\\t',names=['id', 'query', 'candidate', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['query', 'candidate', 'label']]\n",
    "\n",
    "dfs = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "dfs.to_csv('output_data/bot_corpus_20220517_v2.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存处理好的数据-0612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path1 = 'output_data/bot_multi_intent_train_20220517_3.csv'\n",
    "path2 = 'output_data/bot_train_20220612_v2_50_1.csv'\n",
    "path3 = 'data/wz_train.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1, sep='\\t')\n",
    "df2 = pd.read_csv(path2, sep='\\t')\n",
    "df3 = pd.read_csv(path3, sep='\\t',names=['id', 'query', 'candidate', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.iloc[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['query', 'candidate', 'label']]\n",
    "\n",
    "dfs = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "dfs.to_csv('output_data/bot_corpus_20220612_v4.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafaadbda7e2b4673c53a13d22366aab1c2a35a28f6b7c4e8046d1a490edd4db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
